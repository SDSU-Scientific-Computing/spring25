{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Blocked Matrix-Matrix Multiplication\n",
    "\n",
    "Last time:\n",
    "\n",
    "- CPU optimization\n",
    "\n",
    "Today:\n",
    "\n",
    "1. [Blocked matrix-matrix multiply](#blocked-matrix-matrix-multiply)\n",
    "2. [Blocking for registers](#blocking-for-registers)\n",
    "3. [Optimizing the micro kernel](#optimizing-the-micro-kernel)\n",
    "4. [SIMD.jl](#simd-jl)\n",
    "5. [Constant sized arrays: `StaticArrays.jl`](#constant-sized-arrays-staticarrays-jl)  \n",
    "6. [Loop unrolling](#loop-unrolling)\n",
    "\n",
    "## 1. Blocked matrix-matrix multiply \n",
    "\n",
    "In this lecture, we are primarily concerned about optimizing the code for small matrix-matrix multiplies -- that is problems which fit in the cache; efficient use of the cache for large matrices is another topic.\n",
    "\n",
    ":::{tip}\n",
    "For this section, watch the [video 2.2.1](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-basic-idea.html) on the LAFF course to have a basic idea.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key concept for this unit is blocked matrix-matrix multiply. Namely, we will think of the matrices as partitioned into a set of blocks:\n",
    "\n",
    "$$\n",
    "  A =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "     A_{11} & A_{12} & \\dots  & A_{1K}\\\\\n",
    "     \\hline\n",
    "     A_{21} & A_{22} & \\dots  & A_{2K}\\\\\n",
    "     \\hline\n",
    "     \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "     \\hline\n",
    "     A_{M1} & A_{M2} & \\dots  & A_{MK}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "   B =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "     B_{11} & B_{12} & \\dots  & B_{1N}\\\\\n",
    "     \\hline\n",
    "     B_{21} & B_{22} & \\dots  & B_{2N}\\\\\n",
    "     \\hline\n",
    "     \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "     \\hline\n",
    "     B_{K1} & B_{K2} & \\dots  & B_{KN}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "   C =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "      C_{11} & C_{12} & \\dots  & C_{1N}\\\\\n",
    "      \\hline\n",
    "      C_{21} & C_{22} & \\dots  & C_{2N}\\\\\n",
    "      \\hline\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      \\hline\n",
    "      C_{M1} & C_{M2} & \\dots  & C_{MN}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where each block of $C$ is of size $m_{b} \\times n_{b}$. The matrices $A$ and $B$ are partitioned in a _conformal_ manner into $M \\times K$ and $K \\times N$ blocks respectively; the block size associated with $K$ is $k_{b}$.\n",
    "\n",
    "With this partitioning of the matrix, the update for block $IJ$ of $C$ is then\n",
    "\n",
    "$$\n",
    "C_{IJ} := C_{IJ} + \\sum_{P=1}^{K} A_{IP} B_{PJ}\n",
    "$$\n",
    "\n",
    "Two questions:\n",
    "\n",
    " - What sizes to pick for $m_{b}$, $n_{b}$, and $k_{b}$ to have a matrix-matrix multiplication that makes sense (dimension-wise)?\n",
    " - What sizes to pick for $m_{b}$, $n_{b}$, and $k_{b}$ in order to most efficiently use the available resources?\n",
    " - Which of the previous forms of matrix-matrix multiply should be used for the inner block multiply $A_{IP} B_{PJ}$?\n",
    "\n",
    "### Example:\n",
    "\n",
    "If we partition the matrix $C$ into $3 \\times 4$ blocks (that is, $3$ blocks in the row direction and $4$ blocks in the column direction):\n",
    "\n",
    "$$\n",
    "C =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "      C_{11} & C_{12} & C_{12}  & C_{14}\\\\\n",
    "      \\hline\n",
    "      C_{21} & C_{22} & C_{23}  & C_{24}\\\\\n",
    "      \\hline\n",
    "      C_{31} & C_{32} & C_{33}  & C_{34}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "Then we _have to_ partition the matrix $A$ into $3$ blocks in the row direction and the matrix $B$ into $4$ blocks in the column direction:\n",
    "\n",
    "$$\n",
    "A =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{cccc}\n",
    "      &  &   & \\\\\n",
    "      \\hline\n",
    "      &  &   & \\\\\n",
    "      \\hline\n",
    "      &  &   & \n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "   B =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "      &  &  & \\\\\n",
    "      &  &  & \\\\\n",
    "      &  &  & \\\\\n",
    "    \\end{array}\n",
    "   \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Blocking for registers\n",
    "\n",
    ":::{tip}\n",
    "References on the LAFF course to have a basic idea: \n",
    "- [2.3 Blocking for Registers](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-blocking-for-registers.html)\n",
    "- [2.3.1 A simple model of memory and registers](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-a-simple-model-of-memory-and-registers.html)\n",
    ":::\n",
    "\n",
    "Initially we are just going to be concerned about blocking for registers, which\n",
    "means that we want to choose block size $m_b = m_r$ and $ n_b = n_r$ so that $`C_{IJ}`$ fit in registers; see discussion in [2.3.1 A simple model of memory and registers](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-a-simple-model-of-memory-and-registers.html) to have the memory hierarchy triangle in mind. \n",
    "\n",
    "Usually, a typical modern caches hierarchy is composed of:\n",
    "\n",
    "- registers (small, fast, ~ O(10) of `Float64`)\n",
    "- L1 Cache\n",
    "- L2 Cache\n",
    "- L3 Cache\n",
    "- Main memory (big, slow)\n",
    "- Disk memory (huge, very slow)\n",
    "\n",
    "But to extremely simplify things, we can consider just a hierarchy composed of two levels:\n",
    "\n",
    "- registers (small, fast, ~ O(10) of `Float64`)\n",
    "- Main memory (big, slow)\n",
    "\n",
    "Other assumptions/simplifications:\n",
    "\n",
    "- Our processor has only one core.\n",
    "- Moving data between main memory and registers takes time $\\beta_{R \\leftrightarrow M}$ per double. The $R \\leftrightarrow M$ is meant to capture movement between registers ($R$) and memory ($M$).\n",
    "- The registers can hold 64 doubles.\n",
    "- Performing a flop with data in registers takes time $\\gamma_R$.\n",
    "- Data movement and computation cannot overlap.\n",
    "\n",
    "Since we can only have tens of numbers in registers at a time, this means that\n",
    "$m_r$ and $n_r$ are going to be smaller; typically multiples of $4$ do to\n",
    "vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first, naive implementation we could think of would be translated as (in a pseudo-Julia snippet):\n",
    "\n",
    "```julia\n",
    "for J = 1:N\n",
    "  for I = 1:M\n",
    "    for P = 1:K\n",
    "      Load C_{IJ}, Load A_{IP} and B_{PJ}\n",
    "      C_{IJ} := C_{IJ} + A_{IP} B_{PJ}\n",
    "      Store C_{IJ}\n",
    "    end\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "This leads to the following cost:\n",
    "\n",
    "\n",
    "$$\n",
    "2 (M m_r) (N n_r) (K k_r) \\gamma_R + [2 (M m_r) (N n_r) K + (M m_r) N (K k_r) + M(N n_r) (K k_r)  ] \\beta_{R \\leftrightarrow M}  = \\underbrace{2mnk \\gamma_R}_{\\textrm{computation}}  + \\underbrace{ mnk \\left(\\frac{2}{k_r} +\\frac{1}{n_r} + \\frac{1}{m_r}\\right)\\beta_{R \\leftrightarrow M} }_{\\textrm{overhead}}\n",
    "$$\n",
    "\n",
    "where we have used that $m = M m_r$, $n = N n_r$, and $k = K k_r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we realize that we do _not_ need to load/store $C$ every time in the interior loop, we can move the load/store of $C$ outside of the interior loop. This would optimize things a bit  (in the following pseudo-Julia snippet):\n",
    "\n",
    "\n",
    "```julia\n",
    "for J = 1:N\n",
    "  for I = 1:M\n",
    "    Load C_{IJ}\n",
    "    for P = 1:K\n",
    "      Load A_{IP} and B_{PJ}\n",
    "      C_{IJ} := C_{IJ} + A_{IP} B_{PJ}\n",
    "    end\n",
    "    Store C_{IJ}\n",
    "  end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to the following cost:\n",
    "\n",
    "$$\n",
    "2mnk \\gamma_R\n",
    "$$\n",
    "\n",
    "for computation, and the following only for the loads and stores:\n",
    "\n",
    "$$\n",
    "2 m_r n_r M N + MNK (m_r k_r + k_r n_r) = 2mn + mnk \\left(\\frac{1}{n_r} + \\frac{1}{m_r}\\right)\n",
    "$$\n",
    "\n",
    "where, again, we have used that $m = M m_r$, $n = N n_r$, and $k = K k_r$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about $k_r$? Does this need to be small? The answer will be now, because we will perform $A_{IP}B_{PJ}$ using rank-1 updatess;\n",
    "\n",
    "$$\n",
    "A_{IP} B_{JP} =\n",
    "\\tilde{a}_{1}^T b_{1} + \\tilde{a}_{2}^T b_{2} + \\cdots + \\tilde{a}_{k}^T b_{k_r}\n",
    "= \\sum_{p = 1}^{k_r} \\tilde{a}_{p}^T b_{p}.\n",
    "$$\n",
    "\n",
    "Since we only use each vector $\\tilde{a}_{p}^T$ and $b_{p}$ once in the update of $C_{IJ}$ we can let $k_{r} = k$.\n",
    "\n",
    ":::{note}\n",
    "Note that if we moved/permuted the `P` loop earlier we'd save on loading the\n",
    "blocks of $`A`$ or $`B`$ but would pay for extra stores of $`C`$ and it would be\n",
    "a losing strategy, because moving data is much more expensive that computing\n",
    "with data.\n",
    ":::\n",
    "\n",
    "With this the algorithm then becomes:\n",
    "\n",
    "```julia\n",
    "for J = 1:N\n",
    "  for I = 1:M\n",
    "    Load C_{IJ}\n",
    "    Load A_{I} and B_{J}\n",
    "    C_{IJ} := C_{IJ} + A_{I} B_{J}\n",
    "    Store C_{IJ}\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "We call $C_{IJ}$ a _micro-tile_ of $C$, and $A_{I}$ and $B_{J}$ _micro-panels_ of $A$ and $B$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing the micro kernel\n",
    "\n",
    ":::{tip}\n",
    "References on the LAFF course to have a basic idea: \n",
    "- [2.4 Optimizing the Micro-kernel](https://www.cs.utexas.edu/~flame/laff/pfhp/week2-optimizing-the-micro-kernel.html)\n",
    ":::\n",
    "\n",
    "Let's look at a single rank-1 update:\n",
    "\n",
    "$$\n",
    "C_{IJ} = \\tilde{a}_{1}^T b_{1} + \\tilde{a}_{2}^T b_{2} + \\cdots + \\tilde{a}_{k}^T b_{k}\n",
    "$$\n",
    "\n",
    "In code this becomes\n",
    "```julia\n",
    "for p = 1:k        # Loop over vectors\n",
    "  for j = j:mr   # Select element of vector of `b_p`\n",
    "    for i = 1:nr     # Select element of vector of `ãᵀ_p`\n",
    "      C[i, j] = C[i, j] + A[i,p] * B[p, j]\n",
    "    end\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "Let's imagine that the vector register size `nr = 4`, then the removing the inner for-loop we have\n",
    "\n",
    "```julia\n",
    "for p = 1:k        # Loop over vectors\n",
    "  for j = j:mr   # Select element of vector of `b_p`\n",
    "     C[1, j] = C[1, j] + A[1,p] * B[p, j] # multadd\n",
    "     C[2, j] = C[2, j] + A[2,p] * B[p, j] # multadd\n",
    "     C[3, j] = C[3, j] + A[3,p] * B[p, j] # multadd\n",
    "     C[4, j] = C[4, j] + A[4,p] * B[p, j] # multadd\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "- Notice that each of the these is performing the same operation ($\\gamma  = \\alpha * \\beta + \\gamma$) just with different data; note that this is a **fused multiply add (FMA)** type operation. \n",
    "- Modern CPUs have vector registers which allow us to store small vectors (length `~4`) and in the same time it takes to apply an operation to a single number we can apply it to all the elements in the vector register. \n",
    "\n",
    "Thus, we can imagine our code becoming:\n",
    "\n",
    "```julia\n",
    "for p = 1:k        # Loop over vectors\n",
    "  for j = j:mr   # Select element of vector of `b_p`\n",
    "     C[:, j] = C[:, j] + A[:, p] * B[p, j]\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "where all the elements in the column vectors $C[:, j]$ and $A[:, p]$ are handled at once (here we assume that $B[p, j]$ has been put in a vector register with duplicated values for each element). Thus we have sped up our code by a factor of $4$! (Here we assume that all the elements in $A[:, p]$ can be loaded at\n",
    "once, which is true if memory is properly aligned.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [`SIMD.jl`](https://github.com/eschnett/SIMD.jl)\n",
    "\n",
    "- If we were using C or C++ we would need to use the vector intrinsics for the hardware we were targeting. For example, for Intel vector intrinsics see [Intel Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html).\n",
    "- In Julia we can use a more general interface.\n",
    "\n",
    "In Julia, we only need to use the `SIMD.jl` package. To do this you need to add the\n",
    "package to your environment, which can be done from the repl with:\n",
    "```julia\n",
    "]add SIMD\n",
    "```\n",
    "\n",
    "\n",
    "Basic operation we will need:\n",
    "\n",
    " - `vload` to load data from memory into a vector register\n",
    " - `vstore` to store data from a vector register to memory\n",
    "\n",
    "If we were using C and C++ we would need to use a special fma call\n",
    "(`_mm256_fmadd_pd`), but in Julia this is done behind the scenes for us. When\n",
    "`muladd` is called with vector data Julia does the right thing; Julia uses\n",
    "\"multiple dispatch\" to call the right function depending on the argument types.\n",
    "\n",
    "So in psuedo-code we now have:\n",
    "\n",
    "```julia\n",
    "c1 = vload column 1 of C\n",
    "c2 = vload column 2 of C\n",
    "c3 = vload column 3 of C\n",
    "c4 = vload column 4 of C\n",
    "for p = 1:k        # Loop over vectors\n",
    "  ap = vload column p of A\n",
    "\n",
    "  β  = load B[p, 1])\n",
    "  c1 += β * ap\n",
    "\n",
    "  β  = load B[p, 2])\n",
    "  c2 += β * ap\n",
    "\n",
    "  β  = load B[p, 3])\n",
    "  c3 += β * ap\n",
    "\n",
    "  β  = load B[p, 4])\n",
    "  c4 += β * ap\n",
    "end\n",
    "vstore c1 column 1 of C\n",
    "vstore c2 column 2 of C\n",
    "vstore c3 column 3 of C\n",
    "vstore c4 column 4 of C\n",
    "```\n",
    "\n",
    "Since we are loaded data from a matrix, we need to pass a reference / pointer to the first element of the data we want to load. In Julia, `pointer(C)` will be a pointer to the first element of $C$. To get to the next element we want to load we need to \"stride\" by the number of elements in a column of $C$, call it `m`.\n",
    "\n",
    "So our code becomes:\n",
    "\n",
    "```julia\n",
    "# data we are storing\n",
    "T = eltype(C)\n",
    "\n",
    "# size and type of the vector register\n",
    "VecT = Vec{4, T}\n",
    "\n",
    "# vector loads of the data\n",
    "c1 = vload(VecT, pointer(C) + 0m * sizeof(T)) # no stride\n",
    "c2 = vload(VecT, pointer(C) + 1m * sizeof(T)) # stride by m  (skip one column)\n",
    "c3 = vload(VecT, pointer(C) + 2m * sizeof(T)) # stride by 2m (skip two columns)\n",
    "c4 = vload(VecT, pointer(C) + 3m * sizeof(T)) # stride by 3m (skip three columns)\n",
    "```\n",
    "\n",
    "In the pointers you are not striding by the number of elements, but the number\n",
    "of bytes and `sizeof(T)` returns the number of bytes required to store `T`:\n",
    "\n",
    "```julia\n",
    "julia> sizeof(Float64)\n",
    "8\n",
    "\n",
    "julia> sizeof(Float32)\n",
    "4\n",
    "```\n",
    "\n",
    "### Generalizing using Julia magic\n",
    "\n",
    "\n",
    "Above we assumed that `mr` and `nr` were both `4`, ideally we would like to\n",
    "generalize this with loops. We confront too issues with this\n",
    "\n",
    " - where to put each of the column vectors of `C`\n",
    " - how can we make the numbers represented by `mr` and `nr` known at compile\n",
    "   time; the more data we know at compile time the more optimization can occur\n",
    "\n",
    "#### Compile time constants: `Val`\n",
    "\n",
    "\n",
    "To get constants to be known at compile time we use the `Val` construct in\n",
    "Julia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function foo(N)\n",
    "    v = 0\n",
    "    for i = 1:N\n",
    "      v = v + i\n",
    "    end\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bar(::Val{N}) where N\n",
    "    v = 0\n",
    "    for i = 1:N\n",
    "      v = v + i\n",
    "    end\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm foo(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm bar(Val(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the code generated for `bar(Val(10))` just returns `55` whereas the code for `foo(10)` is much more complicated. \n",
    "- In the call to `bar` the for loop is precomputed since the number `10` is known when the code is compiled.\n",
    "- What the `Val(10)` does is it makes the number `10` essentially a type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Val(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The critical thing for us is that this number is now known when the code is compiled (as opposed to at runtime). \n",
    "- The downside of this is that new version of\n",
    "the code must be compiled for each unique input which adds additional overhead to the first time a function is called; `bar(Val(10))` and `bar(Val(20))` result in different compiled code, whereas `foo(10)` and `foo(20)` use the same compiled code.\n",
    "- A similar optimization occurs when `foo` is used with a constant value inside a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function baz()\n",
    "    foo(10)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm baz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is known as _constant propagation_ in Julia, where the return of `foo(10)` can be figured out at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Constant sized arrays: [`StaticArrays.jl`](https://github.com/JuliaArrays/StaticArrays.jl)\n",
    "\n",
    "It is natural define the vector unit as `VecT = Vec{vl, T}` where `vl` is the length of the vector unit. Thus the microcolumns of $C$ and $A$ get broken up into $n_r / v_l$ pieces.\n",
    "\n",
    "Now the question becomes what should we use to handle the `nr` vectors of the\n",
    "microtile?\n",
    "\n",
    "We could do: `c = Array{VecT}(undef, mr_vl, nr)` which would give us an array of size `mv_vl X nr` that can hold vectors. Unfortunately, even though this array is only used in the microkernel, the array `c` will be allocated on\n",
    "the heap and not the stack; for our purposes, you can think of the _stack_ as memory that is local to the function and _heap_ as memory that can hold data needed across functions. If small enough, stack data should just live in registers.\n",
    "\n",
    "How can we get stack (register) allocated arrays in Julia? \n",
    "\n",
    "We need a package called [`StaticArrays.jl`](https://github.com/JuliaArrays/StaticArrays.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"StaticArrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of arrays in `StaticArrays`:\n",
    "  - `SArray`: Arrays whose size is know at compile time and data does not change; if `a` is an `SArray` you CANNOT do `a[1] = 0`.\n",
    "  - `MArray` (mutable arrays): Arrays whose size is know at compile time but that data can change; if `a` is an `MArray` you CAN do `a[1] = 0`\n",
    "Since our data will be changing, we want to store the column vectors as\n",
    "`MArray`s. Our algorithm will become:\n",
    "\n",
    "```julia\n",
    "  # Load the columns of the microtile of C\n",
    "  mr_vl = div(mr, vl)\n",
    "  c = MArray{Tuple{mr_vl, nr}, VecT}(undef)\n",
    "  @inbounds for j = 1:nr\n",
    "    for i = 1:mr_vl\n",
    "      offset = ((i - 1) * vl + (j - 1) * m) * sizeof(T)\n",
    "      c[i, j] = vload(VecT, pointer(C) + offset)\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "and similarly for $`a`$ we want:\n",
    "```julia\n",
    "  a = MVector{mr_vl, VecT}(undef)\n",
    "  @inbounds 4 for p = 1:pend\n",
    "    for i = 1:mr_vl\n",
    "      offset = ((p - 1) * m + (i - 1) * vl) * sizeof(T)\n",
    "      a[i] = vload(VecT, pointer(A) + offset)\n",
    "    end\n",
    "    for j = 1:nr\n",
    "      β = B[p, j]\n",
    "      for i = 1:mr_vl\n",
    "        c[i, j] = muladd(β, a[i], c[i, j])\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "## 6. Loop unrolling\n",
    "\n",
    "Another (and possibly unneeded) optimization is [loop unrolling](https://en.wikipedia.org/wiki/Loop_unrolling). The basic idea of loop unrolling is to change:\n",
    "\n",
    "```julia\n",
    "  @inbounds for j = 1:nr\n",
    "    for i = 1:mr_vl\n",
    "      offset = ((i - 1) * vl + (j - 1) * m) * sizeof(T)\n",
    "      c[i, j] = vload(VecT, pointer(C) + offset)\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "to\n",
    "\n",
    "```julia\n",
    "  c[1,1] = vload(VecT, pointer(C))\n",
    "  c[2,1] = vload(VecT, pointer(C) + m * sizeof(T)\n",
    "  c[1,2] = vload(VecT, pointer(C) + 2 * m * sizeof(T)\n",
    "  c[2,2] = vload(VecT, pointer(C) + 3 * m * sizeof(T)\n",
    "  c[1,3] = vload(VecT, pointer(C) + 4 * m * sizeof(T)\n",
    "  c[2,3] = vload(VecT, pointer(C) + 5 * m * sizeof(T)\n",
    "  c[1,4] = vload(VecT, pointer(C) + 6 * m * sizeof(T)\n",
    "  c[2,4] = vload(VecT, pointer(C) + 7 * m * sizeof(T)\n",
    "  ...\n",
    "```\n",
    "\n",
    "which achieves two things:\n",
    "\n",
    "- Instructions needed to control the flow of the loop is removed\n",
    "- The compiler has more optimizations at its disposal\n",
    "\n",
    "The downside of loop unrolling is that the binary size gets larger and register pressure can increase.\n",
    "\n",
    "The reason I say that this might be unneeded is that for small loops Julia (LLVM) is likely already unrolling the loops; in some little tests I've seen Julia (LLVM) unroll loops of length `36` but I don't know the details of what\n",
    "heuristics are used for this...\n",
    "\n",
    "That said, we can force loop unrolling using the `@unroll` macro from [`KernelAbstractions.jl`](https://github.com/JuliaGPU/KernelAbstractions.jl):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"KernelAbstractions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so that our loop code becomes\n",
    "\n",
    "```julia\n",
    "  @inbounds @unroll for j = 1:nr\n",
    "    @unroll for i = 1:mr_vl\n",
    "      offset = ((i - 1) * vl + (j - 1) * m) * sizeof(T)\n",
    "      c[i, j] = vload(VecT, pointer(C) + offset)\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "We can also ask for a fixed integer unroll factor:\n",
    "\n",
    "```julia\n",
    "  @inbounds @unroll 4 for p = 1:pend\n",
    "    ...\n",
    "  end\n",
    "```\n",
    "\n",
    "which will unroll the loop in factors of `4`, then handle the remainder safely; see the [LLVM Loop Unrolling](https://llvm.org/docs/TransformMetadata.html#loop-unrolling) for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
