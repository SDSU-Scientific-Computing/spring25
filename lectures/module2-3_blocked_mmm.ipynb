{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Blocked Matrix-Matrix Multiplication\n",
    "\n",
    "Last time:\n",
    "\n",
    "- CPU optimization\n",
    "\n",
    "Today:\n",
    "\n",
    "1. [Blocked matrix-matrix multiply](#blocked-matrix-matrix-multiply)\n",
    "2. [Blocking for registers](#blocking-for-registers)\n",
    "3. [Optimizing the micro kernel](#optimizing-the-micro-kernel)\n",
    "4. [SIMD.jl](#simd-jl)\n",
    "5. [Constant sized arrays: `StaticArrays.jl`](#constant-sized-arrays-staticarrays-jl)  \n",
    "6. [Loop unrolling](#loop-unrolling)\n",
    "7. [Examples in Julia](#examples-in-julia)\n",
    "8. [Summary](#summary)\n",
    "\n",
    "## 1. Blocked matrix-matrix multiply \n",
    "\n",
    "In this lecture, we are primarily concerned about optimizing the code for small matrix-matrix multiplies -- that is problems which fit in the cache; efficient use of the cache for large matrices is another topic.\n",
    "\n",
    ":::{tip}\n",
    "For this section, watch the [video 2.2.1](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-basic-idea.html) on the LAFF course to have a basic idea.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key concept for this unit is blocked matrix-matrix multiply. Namely, we will think of the matrices as partitioned into a set of blocks:\n",
    "\n",
    "$$\n",
    "  A =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "     A_{11} & A_{12} & \\dots  & A_{1K}\\\\\n",
    "     \\hline\n",
    "     A_{21} & A_{22} & \\dots  & A_{2K}\\\\\n",
    "     \\hline\n",
    "     \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "     \\hline\n",
    "     A_{M1} & A_{M2} & \\dots  & A_{MK}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "   B =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "     B_{11} & B_{12} & \\dots  & B_{1N}\\\\\n",
    "     \\hline\n",
    "     B_{21} & B_{22} & \\dots  & B_{2N}\\\\\n",
    "     \\hline\n",
    "     \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "     \\hline\n",
    "     B_{K1} & B_{K2} & \\dots  & B_{KN}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "   C =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "      C_{11} & C_{12} & \\dots  & C_{1N}\\\\\n",
    "      \\hline\n",
    "      C_{21} & C_{22} & \\dots  & C_{2N}\\\\\n",
    "      \\hline\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      \\hline\n",
    "      C_{M1} & C_{M2} & \\dots  & C_{MN}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where each block of $C$ is of size $m_{b} \\times n_{b}$. The matrices $A$ and $B$ are partitioned in a _conformal_ manner into $M \\times K$ and $K \\times N$ blocks respectively; the block size associated with $K$ is $k_{b}$.\n",
    "\n",
    "With this partitioning of the matrix, the update for block $IJ$ of $C$ is then\n",
    "\n",
    "$$\n",
    "C_{IJ} := C_{IJ} + \\sum_{P=1}^{K} A_{IP} B_{PJ}\n",
    "$$\n",
    "\n",
    "Two questions:\n",
    "\n",
    " - What sizes to pick for $m_{b}$, $n_{b}$, and $k_{b}$ to have a matrix-matrix multiplication that makes sense (dimension-wise)?\n",
    " - What sizes to pick for $m_{b}$, $n_{b}$, and $k_{b}$ in order to most efficiently use the available resources?\n",
    " - Which of the previous forms of matrix-matrix multiply should be used for the inner block multiply $A_{IP} B_{PJ}$?\n",
    "\n",
    "### Example:\n",
    "\n",
    "If we partition the matrix $C$ into $3 \\times 4$ blocks (that is, $3$ blocks in the row direction and $4$ blocks in the column direction):\n",
    "\n",
    "$$\n",
    "C =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "      C_{11} & C_{12} & C_{12}  & C_{14}\\\\\n",
    "      \\hline\n",
    "      C_{21} & C_{22} & C_{23}  & C_{24}\\\\\n",
    "      \\hline\n",
    "      C_{31} & C_{32} & C_{33}  & C_{34}\n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "Then we _have to_ partition the matrix $A$ into $3$ blocks in the row direction and the matrix $B$ into $4$ blocks in the column direction:\n",
    "\n",
    "$$\n",
    "A =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{cccc}\n",
    "      &  &   & \\\\\n",
    "      \\hline\n",
    "      &  &   & \\\\\n",
    "      \\hline\n",
    "      &  &   & \n",
    "    \\end{array}\n",
    "   \\end{bmatrix},\n",
    "   B =\n",
    "   \\begin{bmatrix}\n",
    "    \\begin{array}{c|c|c|c}\n",
    "      &  &  & \\\\\n",
    "      &  &  & \\\\\n",
    "      &  &  & \\\\\n",
    "    \\end{array}\n",
    "   \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Blocking for registers\n",
    "\n",
    ":::{tip}\n",
    "References on the LAFF course to have a basic idea: \n",
    "- [2.3 Blocking for Registers](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-blocking-for-registers.html)\n",
    "- [2.3.1 A simple model of memory and registers](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-a-simple-model-of-memory-and-registers.html)\n",
    ":::\n",
    "\n",
    "Initially we are just going to be concerned about blocking for registers, which\n",
    "means that we want to choose block size $m_b = m_r$ and $ n_b = n_r$ so that $C_{IJ}$ fit in registers; see discussion in [2.3.1 A simple model of memory and registers](https://www.cs.utexas.edu/users/flame/laff/pfhp/week2-a-simple-model-of-memory-and-registers.html) to have the memory hierarchy triangle in mind. \n",
    "\n",
    "Usually, a typical modern caches hierarchy is composed of:\n",
    "\n",
    "- registers (small, fast, ~ O(10) of `Float64`)\n",
    "- L1 Cache\n",
    "- L2 Cache\n",
    "- L3 Cache\n",
    "- Main memory (big, slow)\n",
    "- Disk memory (huge, very slow)\n",
    "\n",
    "But to extremely simplify things, we can consider just a hierarchy composed of two levels:\n",
    "\n",
    "- registers (small, fast, ~ O(10) of `Float64`)\n",
    "- Main memory (big, slow)\n",
    "\n",
    "Other assumptions/simplifications:\n",
    "\n",
    "- Our processor has only one core.\n",
    "- Moving data between main memory and registers takes time $\\beta_{R \\leftrightarrow M}$ per double. The $R \\leftrightarrow M$ is meant to capture movement between registers ($R$) and memory ($M$).\n",
    "- The registers can hold 64 doubles.\n",
    "- Performing a flop with data in registers takes time $\\gamma_R$.\n",
    "- Data movement and computation cannot overlap.\n",
    "\n",
    "Since we can only have tens of numbers in registers at a time, this means that\n",
    "$m_r$ and $n_r$ are going to be smaller; typically multiples of $4$ do to\n",
    "vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first, naive implementation we could think of would be translated as (in a pseudo-Julia snippet):\n",
    "\n",
    "```julia\n",
    "for J = 1:N\n",
    "  for I = 1:M\n",
    "    for P = 1:K\n",
    "      Load C_{IJ}, Load A_{IP} and B_{PJ}\n",
    "      C_{IJ} := C_{IJ} + A_{IP} B_{PJ}\n",
    "      Store C_{IJ}\n",
    "    end\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "This leads to the following cost:\n",
    "\n",
    "\n",
    "$$\n",
    "2 (M m_r) (N n_r) (K k_r) \\gamma_R + [2 (M m_r) (N n_r) K + (M m_r) N (K k_r) + M(N n_r) (K k_r)  ] \\beta_{R \\leftrightarrow M}  = \\underbrace{2mnk \\gamma_R}_{\\textrm{computation}}  + \\underbrace{ mnk \\left(\\frac{2}{k_r} +\\frac{1}{n_r} + \\frac{1}{m_r}\\right)\\beta_{R \\leftrightarrow M} }_{\\textrm{overhead}}\n",
    "$$\n",
    "\n",
    "where we have used that $m = M m_r$, $n = N n_r$, and $k = K k_r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we realize that we do _not_ need to load/store $C$ every time in the interior loop, we can move the load/store of $C$ outside of the interior loop. This would optimize things a bit  (in the following pseudo-Julia snippet):\n",
    "\n",
    "\n",
    "```julia\n",
    "for J = 1:N\n",
    "  for I = 1:M\n",
    "    Load C_{IJ} into registers\n",
    "    for P = 1:K\n",
    "      Load A_{IP} and B_{PJ}\n",
    "      C_{IJ} := C_{IJ} + A_{IP} B_{PJ}\n",
    "    end\n",
    "    Store C_{IJ} to memory\n",
    "  end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to the following cost:\n",
    "\n",
    "$$\n",
    "2mnk \\gamma_R\n",
    "$$\n",
    "\n",
    "for computation, and the following only for the loads and stores:\n",
    "\n",
    "$$\n",
    "2 m_r n_r M N + MNK (m_r k_r + k_r n_r) = 2mn + mnk \\left(\\frac{1}{n_r} + \\frac{1}{m_r}\\right)\n",
    "$$\n",
    "\n",
    "where, again, we have used that $m = M m_r$, $n = N n_r$, and $k = K k_r$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about $k_r$? Does this need to be small? The answer will be now, because we will perform $A_{IP}B_{PJ}$ using rank-1 updatess:\n",
    "\n",
    "$$\n",
    "A_{IP} B_{JP} =\n",
    "\\tilde{a}_{1}^T b_{1} + \\tilde{a}_{2}^T b_{2} + \\cdots + \\tilde{a}_{k}^T b_{k_r}\n",
    "= \\sum_{p = 1}^{k_r} \\tilde{a}_{p}^T b_{p},\n",
    "$$\n",
    "\n",
    "since we only use each vector $\\tilde{a}_{p}^T$ and $b_{p}$ once in the update of $C_{IJ}$, then we can let $k_{r} = k$.\n",
    "\n",
    ":::{note}\n",
    "Note that if we moved/permuted the `P` loop earlier we'd save on loading the blocks of $A$ or $B$ but would pay for extra stores of $C$ and it would be a losing strategy, because moving data is much more expensive that computing with data.\n",
    ":::\n",
    "\n",
    "With this the algorithm would become:\n",
    "\n",
    "```julia\n",
    "for J = 1:N\n",
    "  for I = 1:M\n",
    "    Load C_{IJ} into registers\n",
    "    Load A_{I} and B_{J} into registers\n",
    "    C_{IJ} := C_{IJ} + A_{I} B_{J} with micro kernel\n",
    "    Store C_{IJ} to memory\n",
    "  end\n",
    "end\n",
    "```\n",
    "\n",
    "We call $C_{IJ}$ a _micro-tile_ of $C$, and $A_{I}$ and $B_{J}$ _micro-panels_ of $A$ and $B$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing the micro kernel\n",
    "\n",
    ":::{tip}\n",
    "References on the LAFF course to have a basic idea: \n",
    "- [2.4 Optimizing the Micro-kernel](https://www.cs.utexas.edu/~flame/laff/pfhp/week2-optimizing-the-micro-kernel.html)\n",
    ":::\n",
    "\n",
    "Let's look at a single rank-1 update:\n",
    "\n",
    "$$\n",
    "C_{IJ} = \\tilde{a}_{1}^T b_{1} + \\tilde{a}_{2}^T b_{2} + \\cdots + \\tilde{a}_{k}^T b_{k}\n",
    "$$\n",
    "\n",
    "In Julia code this becomes\n",
    "\n",
    "```julia\n",
    "  for p = 1:k             # Loop over vectors\n",
    "    for j = j:mr          # Select element of vector of b_p\n",
    "      for i = 1:nr        # Select element of vector of ãᵀ_p\n",
    "        C[i, j] = C[i, j] + A[i,p] * B[p, j]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "Let's imagine that the vector register size `nr = 4`, then the removing the inner for-loop we have\n",
    "\n",
    "```julia\n",
    "  for p = 1:k           # Loop over vectors\n",
    "    for j = j:mr        # Select element of vector of b_p\n",
    "      C[1, j] = C[1, j] + A[1,p] * B[p, j] # multadd\n",
    "      C[2, j] = C[2, j] + A[2,p] * B[p, j] # multadd\n",
    "      C[3, j] = C[3, j] + A[3,p] * B[p, j] # multadd\n",
    "      C[4, j] = C[4, j] + A[4,p] * B[p, j] # multadd\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "- Notice that each of the these is performing the same operation ($\\gamma  = \\gamma + \\alpha * \\beta $) just with different data; note that this is a **fused multiply add (FMA)** type operation. \n",
    "- Modern CPUs have vector registers which allow us to store small vectors (of length `4` here) and in the same time it takes to apply an operation to a single number we can apply it to all the elements in the vector register. \n",
    "\n",
    "Thus, we can imagine our code becoming:\n",
    "\n",
    "```julia\n",
    "  for p = 1:k          # Loop over vectors\n",
    "    for j = j:mr       # Select element of vector of b_p\n",
    "      C[:, j] = C[:, j] + A[:, p] * B[p, j]\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "where all the elements in the column vectors $C[:, j]$ and $A[:, p]$ are handled at once (here we assume that $B[p, j]$ has been put in a vector register that gets reused for each $j$). Thus we have sped up our code by a factor of $4$! (Also, here we have assumed that all the elements in $A[:, p]$ can be loaded at once, which is true if memory is properly aligned.)\n",
    "\n",
    "### Similar vectorization optimization strategies in other languages\n",
    "\n",
    "- Let's look at how different this would look in a C code, with explicitly declared, vendor-specific (Intel's [AVX2 vector instructions set](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) in this case) FMA directives:\n",
    "\n",
    "```C\n",
    "\n",
    "  #include <immintrin.h> /* to use intrinsic functions */\n",
    "\n",
    "  void Gemm_MRxNRKernel( int k, double *A, int ldA, double *B, int ldB, \n",
    "      double *C, int ldC ) \n",
    "  {\n",
    "    /* Declare vector registers to hold 4x4 C and load them */\n",
    "    __m256d gamma_0123_0 = _mm256_loadu_pd( &gamma( 0,0 ) ); \n",
    "    __m256d gamma_0123_1 = _mm256_loadu_pd( &gamma( 0,1 ) ); \n",
    "    __m256d gamma_0123_2 = _mm256_loadu_pd( &gamma( 0,2 ) ); \n",
    "    __m256d gamma_0123_3 = _mm256_loadu_pd( &gamma( 0,3 ) ); \n",
    "      \n",
    "    for ( int p=0; p<k; p++ ){\n",
    "      /* Declare vector register for load/broadcasting beta( p,j ) */\n",
    "      __m256d beta_p_j; \n",
    "      \n",
    "      /* Declare a vector register to hold the current column of A and load it with the four elements of that column. */\n",
    "      __m256d alpha_0123_p = _mm256_loadu_pd( &alpha( 0,p ) ); \n",
    "\n",
    "      /* Load/broadcast beta( p,0 ). */\n",
    "      beta_p_j = _mm256_broadcast_sd( &beta( p, 0) ); \n",
    "      \n",
    "      /* update the first column of C with the current column of A times beta ( p,0 ) */\n",
    "      gamma_0123_0 = _mm256_fmadd_pd( alpha_0123_p, beta_p_j, gamma_0123_0 ); \n",
    "      \n",
    "      /* REPEAT for second, third, and fourth columns of C.  Notice that the current column of A needs not be reloaded. */\n",
    "    }\n",
    "    \n",
    "    /* Store the updated results */\n",
    "    _mm256_storeu_pd( &gamma(0,0), gamma_0123_0 ); \n",
    "    _mm256_storeu_pd( &gamma(0,1), gamma_0123_1 ); \n",
    "    _mm256_storeu_pd( &gamma(0,2), gamma_0123_2 ); \n",
    "    _mm256_storeu_pd( &gamma(0,3), gamma_0123_3 ); \n",
    "  }\n",
    "```\n",
    "\n",
    "- In addition to the above vectorization optimization strategy in C, which involves FMA directives, another popular way to tell the compiler to use single-instruction multiple-data (SIMD) operations is throught the:\n",
    "  * [`#pragma omp simd`](https://www.ibm.com/docs/zh/xl-c-and-cpp-linux/16.1.0?topic=pdop-pragma-omp-simd) directive, which uses the [`OpenMP (Open Multi-Processing)`](https://en.wikipedia.org/wiki/OpenMP) API that supports multi-platform shared-memory multiprocessing programming in C, C++, and Fortran\n",
    "  * `-fopenmp-simd` C/C++ compiler optimization flag option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [`SIMD.jl`](https://github.com/eschnett/SIMD.jl)\n",
    "\n",
    "- If we were using C or C++ we would need to use the vector intrinsics for the hardware we were targeting. For example, for Intel vector intrinsics see [Intel Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html).\n",
    "- In Julia we can use a more general interface.\n",
    "\n",
    "In Julia, we only need to use the `SIMD.jl` package. To do this you need to add the\n",
    "package to your environment, which can be done from the repl with:\n",
    "\n",
    "```julia\n",
    "  ]add SIMD\n",
    "```\n",
    "\n",
    "\n",
    "Basic operation we will need:\n",
    "\n",
    " - `vload` to load data from memory into a vector register\n",
    " - `vstore` to store data from a vector register to memory\n",
    "\n",
    "If we were using C and C++ we would need to use a special *fma* call (`_mm256_fmadd_pd`), but in Julia this is done behind the scenes for us. When `muladd` is called with vector data Julia does the _right thing_; remember that one of the most powerful features of Julia is **dynamic [(multiple) dispatch](https://en.wikipedia.org/wiki/Multiple_dispatch)**, that means:\n",
    "\n",
    "- Functions can have multiple definitions as long each definition restricts the type of the parameters differently. It is the type of the parameters that define which \"definition\" (or \"method\" in Julia terminology) will be called. \n",
    "\n",
    "- This is the way Julia mimics [polymorphism](https://en.wikipedia.org/wiki/Polymorphism_(computer_science)) that some compiled languages (e.g., C++) have.\n",
    "\n",
    "This means that the Julia compiler dispatches to call the right [`muladd`](https://docs.julialang.org/en/v1/base/math/#Base.muladd) function below depending on the argument types.\n",
    "\n",
    "So in psuedo-lowered-code we now have:\n",
    "\n",
    "```julia\n",
    "  c1 = vload column 1 of C\n",
    "  c2 = vload column 2 of C\n",
    "  c3 = vload column 3 of C\n",
    "  c4 = vload column 4 of C\n",
    "\n",
    "  for p = 1:k        # Loop over vectors\n",
    "    ap = vload column p of A\n",
    "\n",
    "    β  = load B[p, 1])\n",
    "    c1 += β * ap\n",
    "\n",
    "    β  = load B[p, 2])\n",
    "    c2 += β * ap\n",
    "\n",
    "    β  = load B[p, 3])\n",
    "    c3 += β * ap\n",
    "\n",
    "    β  = load B[p, 4])\n",
    "    c4 += β * ap\n",
    "  end\n",
    "\n",
    "  vstore c1 column 1 of C\n",
    "  vstore c2 column 2 of C\n",
    "  vstore c3 column 3 of C\n",
    "  vstore c4 column 4 of C\n",
    "```\n",
    "\n",
    "Since we have loaded data from a matrix, we need to pass a reference / pointer to the first element of the data we want to load. In Julia, `pointer(C)` will be a pointer to the first element of $C$ (like in the C programming language). To get to the next element we need to **stride** by the number of elements in a column of $C$, call it `m`.\n",
    "\n",
    "So our code becomes:\n",
    "\n",
    "```julia\n",
    "# data we are storing\n",
    "T = eltype(C)\n",
    "\n",
    "# size and type of the vector register\n",
    "VecT = Vec{4, T}\n",
    "\n",
    "# vector loads of the data\n",
    "c1 = vload(VecT, pointer(C) + 0m * sizeof(T)) # no stride\n",
    "c2 = vload(VecT, pointer(C) + 1m * sizeof(T)) # stride by m  (skip one column)\n",
    "c3 = vload(VecT, pointer(C) + 2m * sizeof(T)) # stride by 2m (skip two columns)\n",
    "c4 = vload(VecT, pointer(C) + 3m * sizeof(T)) # stride by 3m (skip three columns)\n",
    "```\n",
    "\n",
    "In the pointers you are not striding by the number of elements, but the number of bytes, and `sizeof(T)` here returns the number of bytes required to store `T`:\n",
    "\n",
    "```julia\n",
    "julia> sizeof(Float64)\n",
    "8\n",
    "\n",
    "julia> sizeof(Float32)\n",
    "4\n",
    "```\n",
    "\n",
    "### Generalizing using Julia magic\n",
    "\n",
    "\n",
    "Above we assumed that `mr` and `nr` were both `4`, ideally we would like to generalize this with loops. We confront two issues with this\n",
    "\n",
    "- where to put each of the column vectors of `C`\n",
    "- how can we make the numbers represented by `mr` and `nr` known at compile\n",
    "  time; the more data we know at **compile time** the more optimization can occur by the compiler.\n",
    "\n",
    "#### Compile time constants: `Val`\n",
    "\n",
    "\n",
    "To get constants to be known at compile time we use the `Val` construct in\n",
    "Julia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function foo(N)\n",
    "    v = 0\n",
    "    for i = 1:N\n",
    "      v = v + i\n",
    "    end\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bar(::Val{N}) where N\n",
    "    v = 0\n",
    "    for i = 1:N\n",
    "      v = v + i\n",
    "    end\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm foo(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm bar(Val(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the code generated for `bar(Val(10))` just returns `55` whereas the code for `foo(10)` is much more complicated. \n",
    "- In the call to `bar` the for loop is precomputed since the number `10` is known when the code is compiled.\n",
    "- What the `Val(10)` does is it makes the number `10` essentially a type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Val(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The critical thing for us is that this number is now known when the code is _compiled_ (as opposed to at _runtime_). \n",
    "- The downside of this is that new version of the code must be compiled for each unique input which adds additional overhead to the first time a function is called; `bar(Val(10))` and `bar(Val(20))` result in different compiled code, whereas `foo(10)` and `foo(20)` use the same compiled code.\n",
    "- A similar optimization occurs when `foo` is used with a constant value inside a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function baz()\n",
    "    foo(10)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm baz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is known as _constant propagation_ in Julia, where the return of `foo(10)` can be figured out at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cells above, we have used the `@code_llvm` macro, which shows the LLVM (Julia compiler) code generated.\n",
    "- There are different levels of \"lowering\" the code from the high-level Julia (human readable) syntax, to the machine/assembly level. \n",
    "- Refer to the documentation for each of them: \n",
    "    * [`@code_lowered`](https://docs.julialang.org/en/v1/stdlib/InteractiveUtils/#InteractiveUtils.@code_lowered)\n",
    "    * [`@code_typed`](https://docs.julialang.org/en/v1/stdlib/InteractiveUtils/#InteractiveUtils.@code_typed)\n",
    "    * [`@code_warntype`](https://docs.julialang.org/en/v1/stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype)\n",
    "    * [`@code_llvm`](https://docs.julialang.org/en/v1/stdlib/InteractiveUtils/#InteractiveUtils.@code_llvm)\n",
    "    * [`@code_native`](https://docs.julialang.org/en/v1/stdlib/InteractiveUtils/#InteractiveUtils.@code_native)\n",
    "\n",
    "\n",
    "> Recommended Reading:\n",
    "> [How to optimise Julia code: A practical guide](https://viralinstruction.com/posts/optimise/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Constant sized arrays: [`StaticArrays.jl`](https://github.com/JuliaArrays/StaticArrays.jl)\n",
    "\n",
    "It is natural define the vector unit as \n",
    "\n",
    "```julia\n",
    "VecT = Vector{T}(undef,vl)\n",
    "``` \n",
    "\n",
    "where `vl` is the length of the vector unit with unspecified entries (`undef`). Thus the microcolumns of $C$ and $A$ get broken up into $n_r / v_l$ pieces.\n",
    "\n",
    "Now the question becomes, what should we use to handle the `nr` vectors of the microtile?\n",
    "\n",
    "We could do: \n",
    "\n",
    "```julia\n",
    "c = Array{VecT}(undef, mr_vl, nr)\n",
    "```\n",
    "\n",
    "which would give us an array of size `mv_vl * nr` that can hold vectors with unspecified entries (`undef`). Unfortunately, even though this array is only used in the microkernel, the array `c` will be allocated on the _heap_ and not the _stack_; for our purposes, you can think of the _stack_ as memory that is local to the function and _heap_ as memory that can hold data needed across functions. If small enough, stack data should just live in registers.\n",
    "\n",
    "How can we get stack (register) allocated arrays in Julia? \n",
    "\n",
    "We need a package called [`StaticArrays.jl`](https://github.com/JuliaArrays/StaticArrays.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"StaticArrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of arrays in `StaticArrays`:\n",
    "  - `SArray`: Arrays whose size is know at compile time and data does not change; if `a` is an `SArray` you CANNOT do `a[1] = 0`.\n",
    "  - `MArray` (mutable arrays): Arrays whose size is know at compile time but that data can change; if `a` is an `MArray` you CAN do `a[1] = 0`\n",
    "\n",
    "Since our data will be changing, we want to store the column vectors as\n",
    "`MArray`s. Our algorithm will become:\n",
    "\n",
    "```julia\n",
    "  # Load the columns of the microtile of C\n",
    "  mr_vl = div(mr, vl)\n",
    "  c = MArray{Tuple{mr_vl, nr}, VecT}(undef)\n",
    "  @inbounds for j = 1:nr\n",
    "    for i = 1:mr_vl\n",
    "      offset = ((i - 1) * vl + (j - 1) * m) * sizeof(T)\n",
    "      c[i, j] = vload(VecT, pointer(C) + offset)\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "and similarly for $a$ we want:\n",
    "\n",
    "```julia\n",
    "  a = MVector{mr_vl, VecT}(undef)\n",
    "  @inbounds 4 for p = 1:pend\n",
    "    for i = 1:mr_vl\n",
    "      offset = ((p - 1) * m + (i - 1) * vl) * sizeof(T)\n",
    "      a[i] = vload(VecT, pointer(A) + offset)\n",
    "    end\n",
    "    for j = 1:nr\n",
    "      β = B[p, j]\n",
    "      for i = 1:mr_vl\n",
    "        c[i, j] = muladd(β, a[i], c[i, j])\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "## 6. Loop unrolling\n",
    "\n",
    "Another (and possibly unneeded) optimization is [loop unrolling](https://en.wikipedia.org/wiki/Loop_unrolling). The basic idea of loop unrolling is to change:\n",
    "\n",
    "```julia\n",
    "  @inbounds for j = 1:nr\n",
    "    for i = 1:mr_vl\n",
    "      offset = ((i - 1) * vl + (j - 1) * m) * sizeof(T)\n",
    "      c[i, j] = vload(VecT, pointer(C) + offset)\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "to\n",
    "\n",
    "```julia\n",
    "  c[1,1] = vload(VecT, pointer(C))\n",
    "  c[2,1] = vload(VecT, pointer(C) + m * sizeof(T)\n",
    "  c[1,2] = vload(VecT, pointer(C) + 2 * m * sizeof(T)\n",
    "  c[2,2] = vload(VecT, pointer(C) + 3 * m * sizeof(T)\n",
    "  c[1,3] = vload(VecT, pointer(C) + 4 * m * sizeof(T)\n",
    "  c[2,3] = vload(VecT, pointer(C) + 5 * m * sizeof(T)\n",
    "  c[1,4] = vload(VecT, pointer(C) + 6 * m * sizeof(T)\n",
    "  c[2,4] = vload(VecT, pointer(C) + 7 * m * sizeof(T)\n",
    "  ...\n",
    "```\n",
    "\n",
    "which achieves two things:\n",
    "\n",
    "- Instructions needed to control the flow of the loop is removed\n",
    "- The compiler has more optimizations at its disposal\n",
    "\n",
    "The downside of loop unrolling is that the binary size gets larger and register pressure can increase.\n",
    "\n",
    "The reason I say that this might be unneeded is that for small loops Julia (LLVM) is likely already unrolling the loops; in some little tests I've seen Julia (LLVM) unroll loops of length `36` but I don't know the details of what heuristics are used for this...\n",
    "\n",
    "That said, we can force loop unrolling using the `@unroll` macro from [`KernelAbstractions.jl`](https://github.com/JuliaGPU/KernelAbstractions.jl):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"KernelAbstractions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so that our loop code becomes\n",
    "\n",
    "```julia\n",
    "  @inbounds @unroll for j = 1:nr\n",
    "    @unroll for i = 1:mr_vl\n",
    "      offset = ((i - 1) * vl + (j - 1) * m) * sizeof(T)\n",
    "      c[i, j] = vload(VecT, pointer(C) + offset)\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "We can also ask for a fixed integer unroll factor:\n",
    "\n",
    "```julia\n",
    "  @inbounds @unroll 4 for p = 1:pend\n",
    "    ...\n",
    "  end\n",
    "```\n",
    "\n",
    "which will unroll the loop in factors of `4`, then handle the remainder safely; see the [LLVM Loop Unrolling](https://llvm.org/docs/TransformMetadata.html#loop-unrolling) for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Examples in Julia\n",
    "\n",
    "You can find examples of a $4 \\times 4$ micro-kernel implementation in Julia in the [`julia_codes/module2-3/`](https://github.com/sdsu-comp605/spring25/tree/main/julia_codes/module2-3) directory in the class repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "In Section [2. Blocking for registers](#blocking-for-registers) we found the following cost:\n",
    "\n",
    "$$\n",
    "2mnk \\gamma_R\n",
    "$$\n",
    "\n",
    "for computation, and the following only for the loads and stores:\n",
    "\n",
    "$$\n",
    "2 m_r n_r M N + MNK (m_r k_r + k_r n_r) = 2mn + mnk \\left(\\frac{1}{n_r} + \\frac{1}{m_r}\\right). \n",
    "$$\n",
    "\n",
    "The ratio between flops and memory operations between the registers and memory is then \n",
    "\n",
    "$$\n",
    "\\frac{2mnk}{2mn + mnk \\left(\\frac{1}{n_r} + \\frac{1}{m_r}\\right)} \n",
    "$$\n",
    "\n",
    "We can see that if $k$ is large, then $2mn$ (the cost of loading and storing the $m_r \\times n_r$ submatrices of $C$) can be ignored in the denominator, yielding, approximately,\n",
    "\n",
    "$$\n",
    "\\frac{2mnk}{2mn + mnk \\left(\\frac{1}{n_r} + \\frac{1}{m_r}\\right)} = \\frac{2}{\\frac{1}{n_r} + \\frac{1}{m_r}} = \\frac{2}{\\frac{m_r}{m_r n_r} + \\frac{n_r}{m_r n_r}} = \\frac{2 m_r n_r}{{n_r} + {m_r}}\n",
    "$$\n",
    "\n",
    "- This is the ratio of floating point operations to memory operations that we want to be high.\n",
    "\n",
    "- If $m_r = n_r = 4$, then this ratio is 4. \n",
    "\n",
    "- Which means that, for every memory operation (read) of an element of $A$ or $B$, approximately $4$ floating point operations are performed with data that resides in registers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
