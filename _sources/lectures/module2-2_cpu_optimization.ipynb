{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) CPU Optimization: Matrix-Matrix Multiply\n",
    "\n",
    "Last time:\n",
    "- Measuring performance\n",
    "\n",
    "Today: \n",
    "1. Introduction to CPU Optimization  \n",
    "  1.1 Matrix-Matrix Multiply\n",
    "2. Loop ordering\n",
    "\n",
    "## 1. Introduction to CPU Optimization\n",
    "\n",
    "In this module we talk about optimizing matrix-matrix multiply on the CPU. Some of the material here is largely based on the [LAFF-On Programming for High Performance](https://www.cs.utexas.edu/~flame/laff/pfhp/LAFF-On-PfHP.html) of Robert van de Geijn,\n",
    "Margaret Myers, Devangi Parikh, which has a pairing online MOOC: [LAFF-On Programming for High Performance (LAFF-On-PfHP)](https://www.cs.utexas.edu/users/flame/laff/pfhp/LAFF-On-PfHP.html).\n",
    "\n",
    "I encourage you to watch the videos before class. When watching the videos, really you should be watching for the _big picture_ and we will revisit most of the material in lecture as well, mainly you will have a better learning experience if the in class lectures are the first time you've seen some of the material.\n",
    "\n",
    "The MOOC is done using C (not Julia), so some of the syntax and language discussion is not relevant, but the overall ideas apply. \n",
    "\n",
    "Two big differences between the material presented in C Vs Julia:\n",
    "\n",
    "1. Julia starts it's indexing with `1` whereas C uses `0`, so the first element of an array `A` in Julia is:\n",
    "\n",
    "```julia\n",
    "A[1]\n",
    "```\n",
    "\n",
    "whereas in C is:\n",
    "\n",
    "```C\n",
    "A[0]\n",
    "```\n",
    "\n",
    "2. The second difference is that in C, matrices are not\n",
    "really first-class objects so they must be indexed as flat vectors. In Julia, even though behind the scenes everything is a flat vector, we can index into matrices directly.\n",
    "\n",
    "Some additional Julia related material was gleaned from Sacha Verweij's repository [GemmDemo.jl](https://github.com/Sacha0/GemmDemo.jl) and from a former colleague, Maciej Waruszewski's repository [MyJuliaGEMM](https://github.com/mwarusz/MyJuliaGEMM).\n",
    "\n",
    "Why do we care about CPU optimization (and not just MPI). Again, because of this:\n",
    "\n",
    "![42 years of microprocessor data](https://www.karlrupp.net/wp-content/uploads/2018/02/42-years-processor-trend.png)\n",
    "\n",
    "Source: [Microprocessor Trend Data](https://github.com/karlrupp/microprocessor-trend-data).\n",
    "\n",
    "> Related videos and texts: \n",
    "> - [1.1.1 Launch, part 1](https://www.youtube.com/watch?v=knTLy1j-rco) (time 7:51), [text](https://www.cs.utexas.edu/~flame/laff/pfhp/week1-launch.html)\n",
    "> - [GFLOPS](https://www.youtube.com/watch?v=cRyVMrNNRCk) (time: 5:31), [text](https://www.cs.utexas.edu/~flame/laff/pfhp/week1-launch.html)\n",
    "> - [1.2.2  The leading dimension of a matrix](https://www.youtube.com/watch?v=PhjildK5oO8) \n",
    "(time: 4:02), [text](https://www.cs.utexas.edu/~flame/laff/pfhp/week1-the-leading-dimension.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Matrix-Matrix Multiply\n",
    "\n",
    "We will focus on matrix-matrix multiplication:\n",
    "\n",
    "$$\n",
    "C = C + A * B\n",
    "$$\n",
    "\n",
    "where $C$ is $m \\times n$, $A$ is $m \\times k$, and $B$ is $k \\times n$.\n",
    "\n",
    "The formula we learn for this in Linear Algebra is the following:\n",
    "\n",
    "$$\n",
    "γ_{ij} = γ_{ij} + \\sum_{p=1}^{k} α_{ip} β_{pj}\n",
    "$$\n",
    "\n",
    "where $γ_{ij}$, $α_{ip}$, and $β_{pj}$ are the elements of the matrices $C$, $A$, and $B$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation\n",
    "See [text 1.3.1 Notation](https://www.cs.utexas.edu/~flame/laff/pfhp/week1-notation.html).\n",
    "\n",
    " - Capital letters for matrices $A$, $B$, etc.\n",
    " - lower case letters for vectors $a$, $b$, etc.\n",
    " - lower case Greek letters for floating point scalars\n",
    "   $α$ (corresponds to matrix $A$),\n",
    "   $β$ (corresponds to matrix $B$),\n",
    "   $γ$ (corresponds to matrix $C$),\n",
    " - lower case letters for integer scalars $n$, $m$, $k$ (for matrix sizes) and $i$, $j$, $p$ for element indices\n",
    " - Often useful to think of matrices as collections of column and/or row vectors: \n",
    " \n",
    "If $A$ is a $m \\times k$ matrix, then we expose its columns as\n",
    "\n",
    "$$\n",
    " A = [a_1 | a_2 | \\dots | a_k] \n",
    "$$\n",
    "\n",
    "so that $a_j$ equals the column with index $j$.\n",
    "\n",
    "We can expose its rows as:\n",
    "\n",
    "$$\n",
    "  A =\n",
    "   \\begin{bmatrix}\n",
    "     \\tilde{a}_{1}^{T}\\\\\n",
    "     \\tilde{a}_{2}^{T}\\\\\n",
    "     \\ddots\\\\\n",
    "     \\tilde{a}_{m}^{T}\n",
    "   \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "so that $\\tilde{a}_{i}$ equals the row at index $i$. Here the $^T$ indicates it is a row (a column vector that has been transposed). The tilde is added for clarity since $a^T_i$  would in this setting equal the column indexed with $i$ that has been transposed, rather than the row indexed with $i$ or any subset of the vector. When there isn't a cause for confusion, we will sometimes leave the tilde off.  \n",
    "\n",
    "- Note that we think of all vectors as column vectors by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loop ordering\n",
    "\n",
    "See [text 1.2.4 Ordering the loops](https://www.cs.utexas.edu/~flame/laff/pfhp/week1-ordering-the-loops.html).\n",
    "\n",
    "When the above formula is implemented as a triply nested loop:\n",
    "\n",
    "```julia\n",
    "  for i = 1:m\n",
    "    for j = 1:n\n",
    "      for p = 1:k\n",
    "        C[i, j] += A[i, p] * B[p, j]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "```\n",
    "\n",
    "The loop ordering does not impact the correctness of the algorithm. Each of the loop orderings can be interpreted slightly differently. \n",
    "\n",
    "In the example above, we call \"ijp\" the loop ordering, since the loop index variables appear from outer most loop to inner most loop this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loop ordering: ijp\n",
    "\n",
    "Row vectors of $A$ times the matrix $B$ (update rows of $C$):\n",
    "\n",
    "$$\n",
    "  \\tilde{c}_{i}^T = \\tilde{c}_{i}^{T} + \\tilde{a}_{i}^T B\n",
    "$$\n",
    "\n",
    "with inner $\\tilde{a}_{i}^T B$ computed using dot products (update $\\gamma_{ij}$):\n",
    "\n",
    "$$\n",
    "   \\tilde{a}_{i}^T B =\n",
    "   \\begin{bmatrix}\n",
    "     \\tilde{a}_{i}^T b_1 & \\cdots & \\tilde{a}_{i}^T b_m\n",
    "   \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Example in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row vectors of A times the matrix B (update rows of `C`) with inner dot product\n",
    "function mygemm_ijp!(C, A, B)\n",
    "  n, k = size(A)\n",
    "  _, m = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (n, m)\n",
    "  for i = 1:m\n",
    "    for j = 1:n\n",
    "      for p = 1:k\n",
    "        @inbounds C[i, j] += A[i, p] * B[p, j]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "In the code above (and codes below) we have used the `@inbounds` macro in Julia. This tells the compiler to avoid [bounds checking](https://docs.julialang.org/en/v1/devdocs/boundscheck/) that would normally be applied to ensure program safety when accessing arrays. Use this to improve runtime performance _only if_ you are extremely confident that your code might not try to access/read/write out of bounds data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loop ordering: ipj\n",
    "\n",
    "Row vectors of $A$ times the matrix $B$ (update rows of $C$):\n",
    "\n",
    "$$\n",
    "  \\tilde{c}_{i}^T = \\tilde{c}_{i}^{T} + \\tilde{a}_{i}^T B\n",
    "$$\n",
    "\n",
    "but this time with inner product $\\tilde{a}_{i}^T B$ computed using [`axpy`](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms), scalar times vector plus vector (update rows of C, $\\tilde{c}_{i}^T$):\n",
    "\n",
    "$$\n",
    "   \\tilde{a}_{i}^T B = \\sum_{p=1}^{k} \\alpha_{ip} \\tilde{b}_p^T\n",
    "$$\n",
    "\n",
    "Example in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row vectors of A times the matrix B (update rows of `C`) with inner `axpy`\n",
    "function mygemm_ipj!(C, A, B)\n",
    "    n, k = size(A)\n",
    "    _, m = size(B)\n",
    "    @assert size(B, 1) == k\n",
    "    @assert size(C) == (n, m)\n",
    "\n",
    "    for i = 1:m\n",
    "      for p = 1:k\n",
    "        for j = 1:n\n",
    "          @inbounds C[i, j] += A[i, p] * B[p, j]\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Loop ordering: pij\n",
    "\n",
    "Rank one update (repeatedly update all elements of $C$)\n",
    "\n",
    "$$\n",
    "  C = C + \\sum_{p=1}^{k} a_{p} \\tilde{b}_{p}^T\n",
    "$$\n",
    "\n",
    "with outer product computed using `axpy` with vector $\\tilde{b}_{p}^{T}$\n",
    "\n",
    "$$\n",
    "  a_{p} \\tilde{b}_{p}^T =\n",
    "  \\begin{bmatrix}\n",
    "    \\alpha_{1p} \\tilde{b}_{p}^T\\\\\n",
    "    \\vdots\\\\\n",
    "    \\alpha_{np} \\tilde{b}_{p}^T\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Example in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using `axpy` with rows of `B`\n",
    "function mygemm_pij!(C, A, B)\n",
    "    n, k = size(A)\n",
    "    _, m = size(B)\n",
    "    @assert size(B, 1) == k\n",
    "    @assert size(C) == (n, m)\n",
    "\n",
    "    for p = 1:k\n",
    "      for i = 1:m\n",
    "        for j = 1:n\n",
    "          @inbounds C[i, j] += A[i, p] * B[p, j]\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Loop ordering: pji\n",
    "\n",
    "Rank one update (repeatedly update all elements of $C$)\n",
    "\n",
    "$$\n",
    "  C = C + \\sum_{p=1}^{k} a_{p} \\tilde{b}_{p}^T\n",
    "$$\n",
    "\n",
    "with outer product computed using `axpy` with vector $a_{p}$\n",
    "\n",
    "$$\n",
    "  a_{p} \\tilde{b}_{p}^T =\n",
    "  \\begin{bmatrix}\n",
    "    a_{p} \\beta_{p1} & \\cdots & a_{p} \\beta_{pm}\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Example in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using `axpy` with columns of `A`\n",
    "function mygemm_pji!(C, A, B)\n",
    "    n, k = size(A)\n",
    "    _, m = size(B)\n",
    "    @assert size(B, 1) == k\n",
    "    @assert size(C) == (n, m)\n",
    "\n",
    "    for p = 1:k\n",
    "      for j = 1:n\n",
    "        for i = 1:m\n",
    "          @inbounds C[i, j] += A[i, p] * B[p, j]\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Loop ordering: jpi\n",
    "\n",
    "Matrix times column vector (update columns of $C$)\n",
    "\n",
    "$$\n",
    "  c_j = c_{j} + A b_j\n",
    "$$\n",
    "\n",
    "with inner products $A b_j$ computed using `axpy`:\n",
    "\n",
    "$$\n",
    "  A b_j = \\sum_{p=1}^{k} a_{p}\\beta_{pj}\n",
    "$$\n",
    "\n",
    "Example in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix times column vector (update columns of `C`) with inner `axpy`\n",
    "function mygemm_jpi!(C, A, B)\n",
    "    n, k = size(A)\n",
    "    _, m = size(B)\n",
    "    @assert size(B, 1) == k\n",
    "    @assert size(C) == (n, m)\n",
    "\n",
    "    for j = 1:n\n",
    "      for p = 1:k\n",
    "        for i = 1:m\n",
    "          @inbounds C[i, j] += A[i, p] * B[p, j]\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.6 Loop ordering: jip\n",
    "\n",
    "Matrix times column vector (update columns of $C$)\n",
    "\n",
    "$$\n",
    "  c_j = c_{j} + A b_j\n",
    "$$\n",
    "\n",
    "with inner products $A b_j$ computed using dot products\n",
    "\n",
    "$$\n",
    "  A b_j =\n",
    "  \\begin{bmatrix}\n",
    "    \\tilde{a}_{1}^{T} b_{j}\\\\\n",
    "    \\vdots\\\\\n",
    "    \\tilde{a}_{n}^{T} b_{j}\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Example in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix times column vector (update columns of `C`) with inner dot product\n",
    "function mygemm_jip!(C, A, B)\n",
    "    n, k = size(A)\n",
    "    _, m = size(B)\n",
    "    @assert size(B, 1) == k\n",
    "    @assert size(C) == (n, m)\n",
    "\n",
    "    for j = 1:n\n",
    "      for i = 1:m\n",
    "        for p = 1:k\n",
    "          @inbounds C[i, j] += A[i, p] * B[p, j]\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "  end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "We now want to test all these different implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What modules / packages do we depend on\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Printf\n",
    "using Plots\n",
    "default(linewidth=4) # Plots embelishments\n",
    "\n",
    "# To ensure repeatability\n",
    "Random.seed!(777)\n",
    "\n",
    "# Don't let BLAS use lots of threads (since we are not multi-threaded yet!)\n",
    "BLAS.set_num_threads(1)\n",
    "\n",
    "# C := α * A * B + β * C\n",
    "refgemm!(C, A, B) = mul!(C, A, B, one(eltype(C)), one(eltype(C)))\n",
    "\n",
    "# Algo 2.1: matrix times row vector (update rows of `C`) with inner dot product\n",
    "mygemm! = mygemm_ijp!\n",
    "\n",
    "# Algo 2.2: matrix times row vector (update rows of `C`) with inner axpy\n",
    "# mygemm! = mygemm_ipj!\n",
    "\n",
    "# Algo 2.3: Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using axpy with rows of `B`\n",
    "# mygemm! = mygemm_pij!\n",
    "\n",
    "# Algo 2.4: Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using axpy with columns of `A`\n",
    "# mygemm! = mygemm_pji!\n",
    "\n",
    "# Algo 2.5: matrix times column vector (update columns of `C`) with inner axpy\n",
    "# mygemm! = mygemm_jpi!\n",
    "\n",
    "# Algo 2.6: matrix times column vector (update columns of `C`) with inner dot product\n",
    "# mygemm! = mygemm_jip!\n",
    "\n",
    "num_reps = 3\n",
    "\n",
    "# What precision numbers to use\n",
    "# FloatType = Float32\n",
    "FloatType = Float64\n",
    "\n",
    "@printf(\"size |      reference      |           %s\\n\", mygemm!)\n",
    "@printf(\"     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\\n\")\n",
    "\n",
    "N = 48:48:480\n",
    "best_perf = zeros(length(N))\n",
    "# Size of square matrix to consider\n",
    "for nmk in N\n",
    "  i = Int(nmk / 48)\n",
    "  n = m = k = nmk\n",
    "  @printf(\"%4d |\", nmk)\n",
    "\n",
    "  gflops = 2 * m * n * k * 1e-09\n",
    "\n",
    "  # Create some random initial data\n",
    "  A = rand(FloatType, m, k)\n",
    "  B = rand(FloatType, k, n)\n",
    "  C = rand(FloatType, m, n)\n",
    "\n",
    "  # Make a copy of C for resetting data later\n",
    "  C_old = copy(C)\n",
    "\n",
    "  # \"truth\"\n",
    "  C_ref = A * B + C\n",
    "\n",
    "  # Compute the reference timings\n",
    "  best_time = typemax(FloatType)\n",
    "  for iter = 1:num_reps\n",
    "    # Reset C to the original data\n",
    "    C .= C_old;\n",
    "    run_time = @elapsed refgemm!(C, A, B);\n",
    "    best_time = min(run_time, best_time)\n",
    "  end\n",
    "  # Make sure that we have the right answer!\n",
    "  @assert C ≈ C_ref\n",
    "  best_perf[i] = gflops / best_time\n",
    "\n",
    "  # Print the reference implementation timing\n",
    "  @printf(\"  %4.2e %8.2f  |\", best_time, best_perf[i])\n",
    "\n",
    "  # Compute the timing for mygemm! implementation\n",
    "  best_time = typemax(FloatType)\n",
    "  for iter = 1:num_reps\n",
    "    # Reset C to the original data\n",
    "    C .= C_old;\n",
    "    run_time = @elapsed mygemm!(C, A, B);\n",
    "    best_time = min(run_time, best_time)\n",
    "  end\n",
    "  best_perf[i] = gflops / best_time\n",
    "\n",
    "  # Compute the error (difference between our implementation and the reference)\n",
    "  diff = norm(C - C_ref, Inf)\n",
    "\n",
    "  # Print mygemm! implementations\n",
    "  @printf(\"  %4.2e %8.2f   %.2e\", best_time, best_perf[i], diff)\n",
    "\n",
    "  @printf(\"\\n\")\n",
    "end\n",
    "\n",
    "plot!(N, best_perf, xlabel = \"m = n = k\", ylabel = \"GFLOPs/S\", label = \"$mygemm!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions and observations:\n",
    "\n",
    "- Why do some orderings get better performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
